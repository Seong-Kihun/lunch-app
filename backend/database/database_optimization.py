#!/usr/bin/env python3
"""
ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
ì¸ë±ìŠ¤ ìƒì„±, ì¿¼ë¦¬ ìµœì í™”, ì„±ëŠ¥ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import sys
import os
import time
from datetime import datetime

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from backend.app.extensions import db
# ë ˆê±°ì‹œ import ì œê±° - CLIì—ì„œ create_app() ì‚¬ìš©
from backend.auth.models import User, Friendship
from backend.models.app_models import Party, PartyMember, Restaurant, Review, UserActivity

class DatabaseOptimizer:
    def __init__(self):
        self.optimization_results = []
        self.start_time = datetime.now()

    def log(self, message, level="INFO"):
        """ìµœì í™” ë¡œê·¸ ê¸°ë¡"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {level}: {message}"
        self.optimization_results.append(log_entry)
        print(log_entry)

    def analyze_table_sizes(self):
        """í…Œì´ë¸” í¬ê¸° ë¶„ì„"""
        self.log("ğŸ“Š í…Œì´ë¸” í¬ê¸° ë¶„ì„ ì¤‘...")

        with app.app_context():
            tables = [
                ('users', User),
                ('parties', Party),
                ('party_members', PartyMember),
                ('restaurants', Restaurant),
                ('reviews', Review),
                ('friendships', Friendship),
                ('user_activities', UserActivity)
            ]

            for table_name, model in tables:
                try:
                    count = model.query.count()
                    self.log(f"   ğŸ“‹ {table_name}: {count:,}ê°œ ë ˆì½”ë“œ")
                except Exception as e:
                    self.log(f"   âŒ {table_name}: ë¶„ì„ ì‹¤íŒ¨ - {e}", "ERROR")

    def create_indexes(self):
        """ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±"""
        self.log("ğŸ”§ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")

        with app.app_context():
            indexes_to_create = [
                # User í…Œì´ë¸” ì¸ë±ìŠ¤
                "CREATE INDEX IF NOT EXISTS idx_users_employee_id ON users(employee_id)",
                "CREATE INDEX IF NOT EXISTS idx_users_email ON users(email)",

                # Party í…Œì´ë¸” ì¸ë±ìŠ¤
                "CREATE INDEX IF NOT EXISTS idx_parties_host_employee_id ON parties(host_employee_id)",
                "CREATE INDEX IF NOT EXISTS idx_parties_party_date ON parties(party_date)",
                "CREATE INDEX IF NOT EXISTS idx_parties_restaurant_name ON parties(restaurant_name)",

                # PartyMember í…Œì´ë¸” ì¸ë±ìŠ¤
                "CREATE INDEX IF NOT EXISTS idx_party_members_employee_id ON party_members(employee_id)",
                "CREATE INDEX IF NOT EXISTS idx_party_members_party_id ON party_members(party_id)",

                # Restaurant í…Œì´ë¸” ì¸ë±ìŠ¤
                "CREATE INDEX IF NOT EXISTS idx_restaurants_name ON restaurants(name)",
                "CREATE INDEX IF NOT EXISTS idx_restaurants_category ON restaurants(category)",

                # Review í…Œì´ë¸” ì¸ë±ìŠ¤
                "CREATE INDEX IF NOT EXISTS idx_reviews_restaurant_id ON reviews(restaurant_id)",
                "CREATE INDEX IF NOT EXISTS idx_reviews_user_id ON reviews(user_id)",
                "CREATE INDEX IF NOT EXISTS idx_reviews_rating ON reviews(rating)",

                # Friendship í…Œì´ë¸” ì¸ë±ìŠ¤
                "CREATE INDEX IF NOT EXISTS idx_friendships_requester_id ON friendships(requester_id)",
                "CREATE INDEX IF NOT EXISTS idx_friendships_receiver_id ON friendships(receiver_id)",
                "CREATE INDEX IF NOT EXISTS idx_friendships_status ON friendships(status)",

                # UserActivity í…Œì´ë¸” ì¸ë±ìŠ¤
                "CREATE INDEX IF NOT EXISTS idx_user_activities_user_id ON user_activities(user_id)",
                "CREATE INDEX IF NOT EXISTS idx_user_activities_activity_type ON user_activities(activity_type)",
                "CREATE INDEX IF NOT EXISTS idx_user_activities_created_at ON user_activities(created_at)"
            ]

            created_count = 0
            failed_count = 0

            for index_sql in indexes_to_create:
                try:
                    db.session.execute(db.text(index_sql))
                    created_count += 1
                    index_name = index_sql.split("idx_")[1].split(" ")[0]
                    self.log(f"   âœ… ì¸ë±ìŠ¤ ìƒì„±: {index_name}")
                except Exception as e:
                    failed_count += 1
                    self.log(f"   âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}", "ERROR")

            db.session.commit()
            self.log(f"ğŸ“Š ì¸ë±ìŠ¤ ìƒì„± ê²°ê³¼: {created_count}ê°œ ì„±ê³µ, {failed_count}ê°œ ì‹¤íŒ¨")

    def analyze_query_performance(self):
        """ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„"""
        self.log("âš¡ ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ ì¤‘...")

        with app.app_context():
            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
            test_queries = [
                ("ì‚¬ìš©ì ì¡°íšŒ (employee_id)", lambda: User.query.filter_by(employee_id=1).first()),
                ("íŒŒí‹° ëª©ë¡ ì¡°íšŒ", lambda: Party.query.filter_by(host_employee_id=1).all()),
                ("íŒŒí‹° ë©¤ë²„ ì¡°íšŒ", lambda: PartyMember.query.filter_by(employee_id=1).all()),
                ("ì‹ë‹¹ ê²€ìƒ‰", lambda: Restaurant.query.filter(Restaurant.name.like('%ì‹ë‹¹%')).all()),
                ("ë¦¬ë·° ì¡°íšŒ", lambda: Review.query.filter_by(restaurant_id=1).all()),
                ("ì¹œêµ¬ ëª©ë¡ ì¡°íšŒ", lambda: Friendship.query.filter_by(requester_id=1).all()),
                ("ì‚¬ìš©ì í™œë™ ì¡°íšŒ", lambda: UserActivity.query.filter_by(user_id=1).all())
            ]

            query_results = []

            for query_name, query_func in test_queries:
                try:
                    start_time = time.time()
                    result = query_func()
                    execution_time = (time.time() - start_time) * 1000  # ms

                    result_count = len(result) if isinstance(result, list) else (1 if result else 0)
                    query_results.append((query_name, execution_time, result_count, "ì„±ê³µ"))

                    self.log(f"   âš¡ {query_name}: {execution_time:.2f}ms ({result_count}ê°œ ê²°ê³¼)")

                except Exception as e:
                    query_results.append((query_name, 0, 0, f"ì‹¤íŒ¨: {str(e)[:50]}"))
                    self.log(f"   âŒ {query_name}: ì‹¤íŒ¨ - {e}", "ERROR")

            # ì„±ëŠ¥ í†µê³„
            successful_queries = [q for q in query_results if q[3] == "ì„±ê³µ"]
            if successful_queries:
                avg_time = sum(q[1] for q in successful_queries) / len(successful_queries)
                max_time = max(q[1] for q in successful_queries)
                min_time = min(q[1] for q in successful_queries)

                self.log("ğŸ“Š ì¿¼ë¦¬ ì„±ëŠ¥ í†µê³„:")
                self.log(f"   í‰ê·  ì‹¤í–‰ì‹œê°„: {avg_time:.2f}ms")
                self.log(f"   ìµœëŒ€ ì‹¤í–‰ì‹œê°„: {max_time:.2f}ms")
                self.log(f"   ìµœì†Œ ì‹¤í–‰ì‹œê°„: {min_time:.2f}ms")

                # ëŠë¦° ì¿¼ë¦¬ ì‹ë³„
                slow_queries = [q for q in successful_queries if q[1] > 100]  # 100ms ì´ìƒ
                if slow_queries:
                    self.log(f"âš ï¸ ëŠë¦° ì¿¼ë¦¬ ({len(slow_queries)}ê°œ):")
                    for query_name, exec_time, _, _ in slow_queries:
                        self.log(f"   â€¢ {query_name}: {exec_time:.2f}ms")

    def optimize_database_settings(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ìµœì í™”"""
        self.log("âš™ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ìµœì í™” ì¤‘...")

        with app.app_context():
            # SQLite ìµœì í™” ì„¤ì •
            optimization_queries = [
                "PRAGMA journal_mode=WAL",  # Write-Ahead Logging
                "PRAGMA synchronous=NORMAL",  # ì„±ëŠ¥ê³¼ ì•ˆì „ì„±ì˜ ê· í˜•
                "PRAGMA cache_size=10000",  # ìºì‹œ í¬ê¸° ì¦ê°€
                "PRAGMA temp_store=MEMORY",  # ì„ì‹œ í…Œì´ë¸”ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
                "PRAGMA mmap_size=268435456",  # 256MB ë©”ëª¨ë¦¬ ë§µí•‘
                "PRAGMA optimize"  # ì¿¼ë¦¬ ìµœì í™”
            ]

            for query in optimization_queries:
                try:
                    db.session.execute(db.text(query))
                    self.log(f"   âœ… ì„¤ì • ì ìš©: {query}")
                except Exception as e:
                    self.log(f"   âŒ ì„¤ì • ì‹¤íŒ¨: {query} - {e}", "ERROR")

            db.session.commit()

    def vacuum_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ë° ì••ì¶•"""
        self.log("ğŸ§¹ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì¤‘...")

        with app.app_context():
            try:
                # VACUUM ì‹¤í–‰ (SQLite)
                db.session.execute(db.text("VACUUM"))
                db.session.commit()
                self.log("   âœ… VACUUM ì™„ë£Œ - ë°ì´í„°ë² ì´ìŠ¤ ì••ì¶• ë° ì •ë¦¬")

                # í†µê³„ ì—…ë°ì´íŠ¸
                db.session.execute(db.text("ANALYZE"))
                db.session.commit()
                self.log("   âœ… ANALYZE ì™„ë£Œ - ì¿¼ë¦¬ ìµœì í™” í†µê³„ ì—…ë°ì´íŠ¸")

            except Exception as e:
                self.log(f"   âŒ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}", "ERROR")

    def generate_optimization_report(self):
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        self.log("ğŸ“‹ ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

        end_time = datetime.now()
        duration = end_time - self.start_time

        report = {
            "optimization_info": {
                "start_time": self.start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration_seconds": duration.total_seconds(),
                "status": "completed"
            },
            "results": self.optimization_results,
            "recommendations": [
                "ì •ê¸°ì ì¸ VACUUM ì‹¤í–‰ (ì£¼ 1íšŒ)",
                "ì¿¼ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
                "ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  ë¶„ì„",
                "ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ëª¨ë‹ˆí„°ë§"
            ]
        }

        # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        report_file = f"database_optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            import json
            json.dump(report, f, indent=2, ensure_ascii=False)

        self.log(f"âœ… ìµœì í™” ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
        return report_file

    def run_optimization(self):
        """ì „ì²´ ìµœì í™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        self.log("ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹œì‘")
        self.log("=" * 50)

        try:
            # 1. í…Œì´ë¸” í¬ê¸° ë¶„ì„
            self.analyze_table_sizes()

            # 2. ì¸ë±ìŠ¤ ìƒì„±
            self.create_indexes()

            # 3. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ìµœì í™”
            self.optimize_database_settings()

            # 4. ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„
            self.analyze_query_performance()

            # 5. ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬
            self.vacuum_database()

            # 6. ë¦¬í¬íŠ¸ ìƒì„±
            report_file = self.generate_optimization_report()

            self.log("ğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ!")
            self.log("=" * 50)
            self.log("ğŸ“‹ ìµœì í™” ê²°ê³¼:")
            self.log("   âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            self.log("   âœ… ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ")
            self.log("   âœ… ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ìµœì í™” ì™„ë£Œ")
            self.log("   âœ… ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            self.log(f"   ğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸: {report_file}")

            return True

        except Exception as e:
            self.log(f"âŒ ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "ERROR")
            return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ë„êµ¬")
    print("=" * 50)

    optimizer = DatabaseOptimizer()

    try:
        success = optimizer.run_optimization()

        if success:
            print("\nğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            return 0
        else:
            print("\nâŒ ìµœì í™” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return 1

    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
